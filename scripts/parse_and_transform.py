from bs4 import BeautifulSoup
import pandas as pd
import re
import os

# Verificar que el folder "silver/" existe para almacenar los archivos parquet
output_dir = "silver"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Los headers que queremos buscar y los textos específicos a extraer de cada tabla
# por conveniencia se especificaron solo algunos valores relevantes
headers_and_keywords = {
    "CONSOLIDATED STATEMENTS OF OPERATIONS": ["Total net sales", "Total cost of sales", "Total operating expenses", "Net income"],
    "CONSOLIDATED BALANCE SHEETS": ["Total current assets", "Total assets", "Total current liabilities", "Total liabilities", "Total liabilities and shareholders equity"],
    "CONSOLIDATED STATEMENTS OF CASH FLOWS": ["Net income", "Cash generated by operating activities", "Cash used in financing activities"]
}

# To int
def convert_to_int(value):
    # Eliminar caracteres no numericos (como comas y simbolo de dinero)
    cleaned_value = re.sub(r'[^\d.-]', '', value)

    return int(cleaned_value)


# Lista de años de los archivos HTML
years = [2020, 2021, 2022]

for year in years:
    # Path de los html en "bronze/"
    file_path = os.path.join("bronze", f"aapl_10k_{year}.html")

    # Abrir el archivo en modo lectura
    with open(file_path, 'r', encoding='utf-8') as file:
        soup = BeautifulSoup(file, 'lxml')

    # Lista para almacenar los dataframes de cada seccion
    dfs = []

    # Buscar los headers que esten dentro de <span> y que tengan los textos especificados
    for header_text, keywords in headers_and_keywords.items():
        # Buscar el header con el texto requerido dentro de <span>
        header = soup.find(text=header_text)

        if header:
            # Encontrar la tabla que le sigue al header
            table = header.find_parent().find_next('table')

            # Extraer las filas de la tabla
            rows = table.find_all('tr')

            # Lista para almacenar los datos encontrados
            section_data = {}

            # Buscar sobre los rows de la tabla para buscar los campos con los textos deseados
            for row in rows:
                cells = row.find_all('td')  # Buscar los campos (td) en cada row
                if cells:
                    for keyword in keywords:
                        # Buscar si el texto de la celda contiene el keyword
                        for cell in cells:
                            if keyword.lower() in cell.get_text(strip=True).lower():
                                # Si encontramos el keyword, obtenemos el siguiente valor
                                # Suponiendo que el valor está en la celda siguiente (solo se toma el valor de un año, el año del archivo revisado, que es la primera columna)
                                value = cells[cells.index(cell) + 1].get_text(strip=True) if cells.index(cell) + 1 < len(cells) else "No value found"

                                # Convertir el valor a entero
                                section_data[keyword] = convert_to_int(value)

            # Agregar la columna fiscal_year al dataframe
            section_data['fiscal_year'] = year

            # Agregar los datos de la seccion al dataframe
            df = pd.DataFrame([section_data])

            # Agregar el dataframe a la lista
            dfs.append(df)

            print(f"Header: {header_text} para el año {year}")
            print(df)
            print("\n\n")

            # Guardar el dataframe a un archivo Parquet en el folder 'silver'
            parquet_file_path = os.path.join(output_dir, f'{header_text.replace(" ", "_").replace(",", "")}_{year}.parquet')
            df.to_parquet(parquet_file_path, engine='pyarrow', index=False)  # Usamos pyarrow para guardar el archivo Parquet

        else:
            print(f"El header '{header_text}' no se encuentra en el documento para el año {year}.")
